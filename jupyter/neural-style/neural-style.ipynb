{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neual-style\n",
    "\n",
    "[リポジトリ](https://github.com/jcjohnson/neural-style)\n",
    "\n",
    "論文の理解も浅く、コードも何をやってるのか把握しづらかったため学習用のjupyter notebook file を作成した.  \n",
    "\n",
    "多分これを手元で動かすには以下のことをする必要がある.\n",
    "- torchのセットアップ\n",
    "- luarocksで各種モジュールをインストール\n",
    "- VGG modluesのダウンロード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モジュールの読み込み\n",
    "### About Modules\n",
    "- torch\n",
    "- nn\n",
    "- optim\n",
    "- loadcaffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'image'\n",
    "require 'optim'\n",
    "\n",
    "require 'loadcaffe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各パラメータの設定\n",
    "\n",
    "オリジナルではCmdLineでの指定になっている.  \n",
    "ノート上では構造体？にまとめた."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    -- Basic options\n",
    "    style_image = 'examples/inputs/seated-nude.jpg',\n",
    "    style_blend_weights = 'nil',\n",
    "    content_image = 'examples/inputs/tubingen.jpg',\n",
    "    image_size = 512,\n",
    "    gpu = -1,\n",
    "    multigpu_strategy = '',\n",
    "\n",
    "    -- Optimization options\n",
    "    content_weight = 5e0,\n",
    "    style_weight = 1e2,\n",
    "    tv_weight = 1e-3,\n",
    "    num_iterations = 1000,\n",
    "    normalize_gradients = false,\n",
    "    init = 'random',\n",
    "    init_image = '',\n",
    "    optimizer = 'lbfgs',\n",
    "    learning_rate = 1e1,\n",
    "    lbfgs_num_correction = 0,\n",
    "\n",
    "    -- Output options\n",
    "    print_iter = 50,\n",
    "    save_iter = 100,\n",
    "    output_image = 'out.png',\n",
    "\n",
    "    -- Other options\n",
    "    style_scale = 1.0,\n",
    "    original_colors = 0,\n",
    "    pooling = 'max',\n",
    "    proto_file = 'models/VGG_ILSVRC_19_layers_deploy.prototxt',\n",
    "    model_file = 'models/VGG_ILSVRC_19_layers.caffemodel',\n",
    "    backend = 'nn',\n",
    "    cudnn_autotune = false,\n",
    "    seed = -1,\n",
    "\n",
    "    content_layers = 'relu4_2',\n",
    "    style_layers = 'relu1_1,relu2_1,relu3_1,relu4_1,relu5_1',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  style_weight : 100\n",
       "  pooling : max\n",
       "  seed : -1\n",
       "  content_image : examples/inputs/tubingen.jpg\n",
       "  save_iter : 100\n",
       "  style_scale : 1\n",
       "  style_image : examples/inputs/seated-nude.jpg\n",
       "  optimizer : lbfgs\n",
       "  style_blend_weights : nil\n",
       "  num_iterations : 1000\n",
       "  image_size : 512\n",
       "  content_layers : relu4_2\n",
       "  cudnn_autotune : false\n",
       "  gpu : -1\n",
       "  init_image : \n",
       "  multigpu_strategy : \n",
       "  model_file : models/VGG_ILSVRC_19_layers.caffemodel\n",
       "  print_iter : 50\n",
       "  backend : nn\n",
       "  proto_file : models/VGG_ILSVRC_19_layers_deploy.prototxt\n",
       "  original_colors : 0\n",
       "  output_image : out.png\n",
       "  init : random\n",
       "  normalize_gradients : false\n",
       "  learning_rate : 10\n",
       "  style_layers : relu1_1,relu2_1,relu3_1,relu4_1,relu5_1\n",
       "  content_weight : 5\n",
       "  lbfgs_num_correction : 0\n",
       "  tv_weight : 0.001\n",
       "}\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各種関数について"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPUのセットアップ\n",
    "\n",
    "ただし、今回はCPU環境に限定するためスキップ.  \n",
    "本来であれば、ここでGPU環境が使えるのであればGPU専用のパッケージに切り替える."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "function setup_gpu(params)\n",
    "    local multigpu = false\n",
    "    if params.gpu:find(',') then\n",
    "    multigpu = true\n",
    "    params.gpu = params.gpu:split(',')\n",
    "    for i = 1, #params.gpu do\n",
    "      params.gpu[i] = tonumber(params.gpu[i]) + 1\n",
    "    end\n",
    "  else\n",
    "    params.gpu = tonumber(params.gpu) + 1\n",
    "  end\n",
    "  local dtype = 'torch.FloatTensor'\n",
    "  if multigpu or params.gpu > 0 then\n",
    "    if params.backend ~= 'clnn' then\n",
    "      require 'cutorch'\n",
    "      require 'cunn'\n",
    "      if multigpu then\n",
    "        cutorch.setDevice(params.gpu[1])\n",
    "      else\n",
    "        cutorch.setDevice(params.gpu)\n",
    "      end\n",
    "      dtype = 'torch.CudaTensor'\n",
    "    else\n",
    "      require 'clnn'\n",
    "      require 'cltorch'\n",
    "      if multigpu then\n",
    "        cltorch.setDevice(params.gpu[1])\n",
    "      else\n",
    "        cltorch.setDevice(params.gpu)\n",
    "      end\n",
    "      dtype = torch.Tensor():cl():type()\n",
    "    end\n",
    "  else\n",
    "    params.backend = 'nn'\n",
    "  end\n",
    "\n",
    "  if params.backend == 'cudnn' then\n",
    "    require 'cudnn'\n",
    "    if params.cudnn_autotune then\n",
    "      cudnn.benchmark = true\n",
    "    end\n",
    "    cudnn.SpatialConvolution.accGradParameters = nn.SpatialConvolutionMM.accGradParameters -- ie: nop\n",
    "  end\n",
    "  return dtype, multigpu\n",
    "end\n",
    "\n",
    "-- setup_gpu(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "function build_filename(output_image, iteration)\n",
    "  local ext = paths.extname(output_image)\n",
    "  local basename = paths.basename(output_image, ext)\n",
    "  local directory = paths.dirname(output_image)\n",
    "  return string.format('%s/%s_%d.%s',directory, basename, iteration, ext)\n",
    "end\n",
    "\n",
    "-- Combine the Y channel of the generated image and the UV channels of the\n",
    "-- content image to perform color-independent style transfer.\n",
    "function original_colors(content, generated)\n",
    "  local generated_y = image.rgb2yuv(generated)[{{1, 1}}]\n",
    "  local content_uv = image.rgb2yuv(content)[{{2, 3}}]\n",
    "  return image.yuv2rgb(torch.cat(generated_y, content_uv, 1))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理と戻す関数\n",
    "\n",
    "loadcaffeに持っていくと、カラースケールが変わるためあらかじめ変換する関数."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Preprocess an image before passing it to a Caffe model.\n",
    "-- We need to rescale from [0, 1] to [0, 255], convert from RGB to BGR,\n",
    "-- and subtract the mean pixel.\n",
    "function preprocess(img)\n",
    "  local mean_pixel = torch.DoubleTensor({103.939, 116.779, 123.68})\n",
    "  local perm = torch.LongTensor{3, 2, 1}\n",
    "  img = img:index(1, perm):mul(256.0)\n",
    "  mean_pixel = mean_pixel:view(3, 1, 1):expandAs(img)\n",
    "  img:add(-1, mean_pixel)\n",
    "  return img\n",
    "end\n",
    "\n",
    "\n",
    "-- Undo the above preprocessing.\n",
    "function deprocess(img)\n",
    "  local mean_pixel = torch.DoubleTensor({103.939, 116.779, 123.68})\n",
    "  mean_pixel = mean_pixel:view(3, 1, 1):expandAs(img)\n",
    "  img = img + mean_pixel\n",
    "  local perm = torch.LongTensor{3, 2, 1}\n",
    "  img = img:index(1, perm):div(256.0)\n",
    "  return img\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ContentLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Define an nn Module to compute content loss in-place\n",
    "ContentLoss, parent = torch.class('nn.ContentLoss', 'nn.Module')\n",
    "\n",
    "function ContentLoss:__init(strength, normalize)\n",
    "  parent.__init(self)\n",
    "  self.strength = strength\n",
    "  self.target = torch.Tensor()\n",
    "  self.normalize = normalize or false\n",
    "  self.loss = 0\n",
    "  self.crit = nn.MSECriterion()\n",
    "  self.mode = 'none'\n",
    "end\n",
    "\n",
    "function ContentLoss:updateOutput(input)\n",
    "  if self.mode == 'loss' then\n",
    "    self.loss = self.crit:forward(input, self.target) * self.strength\n",
    "  elseif self.mode == 'capture' then\n",
    "    self.target:resizeAs(input):copy(input)\n",
    "  end\n",
    "  self.output = input\n",
    "  return self.output\n",
    "end\n",
    "\n",
    "function ContentLoss:updateGradInput(input, gradOutput)\n",
    "  if self.mode == 'loss' then\n",
    "    if input:nElement() == self.target:nElement() then\n",
    "      self.gradInput = self.crit:backward(input, self.target)\n",
    "    end\n",
    "    if self.normalize then\n",
    "      self.gradInput:div(torch.norm(self.gradInput, 1) + 1e-8)\n",
    "    end\n",
    "    self.gradInput:mul(self.strength)\n",
    "    self.gradInput:add(gradOutput)\n",
    "  else\n",
    "    self.gradInput:resizeAs(gradOutput):copy(gradOutput)\n",
    "  end\n",
    "  return self.gradInput\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gram, parent = torch.class('nn.GramMatrix', 'nn.Module')\n",
    "\n",
    "function Gram:__init()\n",
    "  parent.__init(self)\n",
    "end\n",
    "\n",
    "function Gram:updateOutput(input)\n",
    "  assert(input:dim() == 3)\n",
    "  local C, H, W = input:size(1), input:size(2), input:size(3)\n",
    "  local x_flat = input:view(C, H * W)\n",
    "  self.output:resize(C, C)\n",
    "  self.output:mm(x_flat, x_flat:t())\n",
    "  return self.output\n",
    "end\n",
    "\n",
    "function Gram:updateGradInput(input, gradOutput)\n",
    "  assert(input:dim() == 3 and input:size(1))\n",
    "  local C, H, W = input:size(1), input:size(2), input:size(3)\n",
    "  local x_flat = input:view(C, H * W)\n",
    "  self.gradInput:resize(C, H * W):mm(gradOutput, x_flat)\n",
    "  self.gradInput:addmm(gradOutput:t(), x_flat)\n",
    "  self.gradInput = self.gradInput:view(C, H, W)\n",
    "  return self.gradInput\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StyleLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Define an nn Module to compute style loss in-place\n",
    "StyleLoss, parent = torch.class('nn.StyleLoss', 'nn.Module')\n",
    "\n",
    "function StyleLoss:__init(strength, normalize)\n",
    "  parent.__init(self)\n",
    "  self.normalize = normalize or false\n",
    "  self.strength = strength\n",
    "  self.target = torch.Tensor()\n",
    "  self.mode = 'none'\n",
    "  self.loss = 0\n",
    "\n",
    "  self.gram = nn.GramMatrix()\n",
    "  self.blend_weight = nil\n",
    "  self.G = nil\n",
    "  self.crit = nn.MSECriterion()\n",
    "end\n",
    "\n",
    "function StyleLoss:updateOutput(input)\n",
    "  self.G = self.gram:forward(input)\n",
    "  self.G:div(input:nElement())\n",
    "  if self.mode == 'capture' then\n",
    "    if self.blend_weight == nil then\n",
    "      self.target:resizeAs(self.G):copy(self.G)\n",
    "    elseif self.target:nElement() == 0 then\n",
    "      self.target:resizeAs(self.G):copy(self.G):mul(self.blend_weight)\n",
    "    else\n",
    "      self.target:add(self.blend_weight, self.G)\n",
    "    end\n",
    "  elseif self.mode == 'loss' then\n",
    "    self.loss = self.strength * self.crit:forward(self.G, self.target)\n",
    "  end\n",
    "  self.output = input\n",
    "  return self.output\n",
    "end\n",
    "\n",
    "function StyleLoss:updateGradInput(input, gradOutput)\n",
    "  if self.mode == 'loss' then\n",
    "    local dG = self.crit:backward(self.G, self.target)\n",
    "    dG:div(input:nElement())\n",
    "    self.gradInput = self.gram:backward(input, dG)\n",
    "    if self.normalize then\n",
    "      self.gradInput:div(torch.norm(self.gradInput, 1) + 1e-8)\n",
    "    end\n",
    "    self.gradInput:mul(self.strength)\n",
    "    self.gradInput:add(gradOutput)\n",
    "  else\n",
    "    self.gradInput = gradOutput\n",
    "  end\n",
    "  return self.gradInput\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TVLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TVLoss, parent = torch.class('nn.TVLoss', 'nn.Module')\n",
    "\n",
    "function TVLoss:__init(strength)\n",
    "    parent.__init(self)\n",
    "    self.strength = strength\n",
    "    self.x_diff = torch.Tensor()\n",
    "    self.y_diff = torch.Tensor()\n",
    "end\n",
    "\n",
    "function TVLoss:updateOutput(input)\n",
    "    self.output = input\n",
    "    return self.output\n",
    "end\n",
    "\n",
    "-- TV loss backward pass inspired by kaishengtai/neuralart\n",
    "function TVLoss:updateGradInput(input, graOutput)\n",
    "    self.gradInput:resizeAs(input):zero()\n",
    "    local C, H, W = input:size(1), input:size(2), input:size(3)\n",
    "    self.x_diff:resize(3, H - 1, W - 1)\n",
    "    self.y_diff:resize(3, H - 1, W - 1)\n",
    "    self.x_diff:copy(input[{{}, {1, -2}, {1, -2}}])\n",
    "    self.x_diff:add(-1, input[{{}, {1, -2}, {2, -1}}])\n",
    "    self.y_diff:copy(input[{{}, {1, -2}, {1, -2}}])\n",
    "    self.y_diff:add(-1, input[{{}, {2, -1}, {1, -2}}])\n",
    "    self.gradInput[{{}, {1, -2}, {1, -2}}]:add(self.x_diff):add(self.y_diff)\n",
    "    self.gradInput[{{}, {1, -2}, {2, -1}}]:add(-1, self.x_diff)\n",
    "    self.gradInput[{{}, {2, -1}, {1, -2}}]:add(-1, self.y_diff)\n",
    "    self.gradInput:mul(self.strength)\n",
    "    self.gradInput:add(gradOutput)\n",
    "    return self.gradInput\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = 'torch.FloatTensor'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loadcaffeの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Successfully loaded models/VGG_ILSVRC_19_layers.caffemodel\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv1_1: 64 3 3 3\n",
       "conv1_2: 64 64 3 3\n",
       "conv2_1: 128 64 3 3\n",
       "conv2_2: 128 128 3 3\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv3_1: 256 128 3 3\n",
       "conv3_2: 256 256 3 3\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv3_3: 256 256 3 3\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv3_4: 256 256 3 3\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv4_1: 512 256 3 3\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv4_2: 512 512 3 3\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv4_3: 512 512 3 3\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv4_4: 512 512 3 3\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv5_1: 512 512 3 3\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv5_2: 512 512 3 3\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv5_3: 512 512 3 3\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv5_4: 512 512 3 3\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "fc6: 1 1 25088 4096\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "fc7: 1 1 4096 4096\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "fc8: 1 1 4096 1000\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local loadcaffe_backend = params.backend\n",
    "if params.backend == 'clnn' then loadcaffe_backend = 'nn' end\n",
    "cnn = loadcaffe.load(params.proto_file, params.model_file, loadcaffe_backend):type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各イメージ画像の読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image = image.load(params.content_image, 3)\n",
    "content_image = image.scale(content_image, params.image_size, 'bilinear')\n",
    "content_image_caffe = preprocess(content_image):float()\n",
    "\n",
    "style_size = math.ceil(params.style_scale * params.image_size)\n",
    "style_image_list = params.style_image:split(',')\n",
    "style_images_caffe = {}\n",
    "for _, img_path in ipairs(style_image_list) do\n",
    "    local img = image.load(img_path, 3)\n",
    "    img = image.scale(img, style_size, 'bilinear')\n",
    "    local img_caffe = preprocess(img):float()\n",
    "    table.insert(style_images_caffe, img_caffe)\n",
    "end\n",
    "\n",
    "init_image = nil\n",
    "if params.init_image ~= '' then\n",
    "    init_image = image.load(params.init_image, 3)\n",
    "    local H, W = content_image:size(2), content_image:size(3)\n",
    "    init_image = image.scale(init_image, W, H, 'bilinear')\n",
    "    init_image = preprocess(init_image):float()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### style image が複数あったときの処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Handle style blending weights for multiple style inputs\n",
    "style_blend_weights = nil\n",
    "if params.style_blend_weights == 'nil' then\n",
    "    -- Style blending not specified, so use equal weighting\n",
    "    style_blend_weights = {}\n",
    "    for i = 1, #style_image_list do\n",
    "      table.insert(style_blend_weights, 1.0)\n",
    "    end\n",
    "else\n",
    "    style_blend_weights = params.style_blend_weights:split(',')\n",
    "    assert(#style_blend_weights == #style_image_list,\n",
    "      '-style_blend_weights and -style_images must have the same number of elements')\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Normalize the style blending weights so they sum to 1\n",
    "style_blend_sum = 0\n",
    "for i = 1, #style_blend_weights do\n",
    "    style_blend_weights[i] = tonumber(style_blend_weights[i])\n",
    "    style_blend_sum = style_blend_sum + style_blend_weights[i]\n",
    "end\n",
    "for i = 1, #style_blend_weights do\n",
    "    style_blend_weights[i] = style_blend_weights[i] / style_blend_sum\n",
    "end\n",
    "\n",
    "content_layers = params.content_layers:split(\",\")\n",
    "style_layers = params.style_layers:split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ネットワークのセットアップ、および損失関数の追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Setting up style layer  \t2\t:\trelu1_1\t\n",
       "Setting up style layer  \t7\t:\trelu2_1\t\n",
       "Setting up style layer  \t12\t:\trelu3_1\t\n",
       "Setting up style layer  \t21\t:\trelu4_1\t\n",
       "Setting up content layer\t23\t:\trelu4_2\t\n",
       "Setting up style layer  \t30\t:\trelu5_1\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Set up the network, inserting style and content loss modules\n",
    "content_losses, style_losses = {}, {}\n",
    "next_content_idx, next_style_idx = 1, 1\n",
    "net = nn.Sequential()\n",
    "  if params.tv_weight > 0 then\n",
    "    local tv_mod = nn.TVLoss(params.tv_weight):type(dtype)\n",
    "    net:add(tv_mod)\n",
    "  end\n",
    "  for i = 1, #cnn do\n",
    "    if next_content_idx <= #content_layers or next_style_idx <= #style_layers then\n",
    "      local layer = cnn:get(i)\n",
    "      local name = layer.name\n",
    "      local layer_type = torch.type(layer)\n",
    "      local is_pooling = (layer_type == 'cudnn.SpatialMaxPooling' or layer_type == 'nn.SpatialMaxPooling')\n",
    "      if is_pooling and params.pooling == 'avg' then\n",
    "        assert(layer.padW == 0 and layer.padH == 0)\n",
    "        local kW, kH = layer.kW, layer.kH\n",
    "        local dW, dH = layer.dW, layer.dH\n",
    "        local avg_pool_layer = nn.SpatialAveragePooling(kW, kH, dW, dH):type(dtype)\n",
    "        local msg = 'Replacing max pooling at layer %d with average pooling'\n",
    "        print(string.format(msg, i))\n",
    "        net:add(avg_pool_layer)\n",
    "      else\n",
    "        net:add(layer)\n",
    "      end\n",
    "      if name == content_layers[next_content_idx] then\n",
    "        print(\"Setting up content layer\", i, \":\", layer.name)\n",
    "        local norm = params.normalize_gradients\n",
    "        local loss_module = nn.ContentLoss(params.content_weight, norm):type(dtype)\n",
    "        net:add(loss_module)\n",
    "        table.insert(content_losses, loss_module)\n",
    "        next_content_idx = next_content_idx + 1\n",
    "      end\n",
    "      if name == style_layers[next_style_idx] then\n",
    "        print(\"Setting up style layer  \", i, \":\", layer.name)\n",
    "        local norm = params.normalize_gradients\n",
    "        local loss_module = nn.StyleLoss(params.style_weight, norm):type(dtype)\n",
    "        net:add(loss_module)\n",
    "        table.insert(style_losses, loss_module)\n",
    "        next_style_idx = next_style_idx + 1\n",
    "      end\n",
    "    end\n",
    "  end\n",
    "  if multigpu then\n",
    "    net = setup_multi_gpu(net, params)\n",
    "  end\n",
    "  net:type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Capturing content targets\t\n",
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> output]\n",
       "  (1): nn.TVLoss\n",
       "  (2): nn.SpatialConvolution(3 -> 64, 3x3, 1,1, 1,1)\n",
       "  (3): nn.ReLU\n",
       "  (4): nn.StyleLoss\n",
       "  (5): nn.SpatialConvolution(64 -> 64, 3x3, 1,1, 1,1)\n",
       "  (6): nn.ReLU\n",
       "  (7): nn.SpatialMaxPooling(2x2, 2,2)\n",
       "  (8): nn.SpatialConvolution(64 -> 128, 3x3, 1,1, 1,1)\n",
       "  (9): nn.ReLU\n",
       "  (10): nn.StyleLoss\n",
       "  (11): nn.SpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)\n",
       "  (12): nn.ReLU\n",
       "  (13): nn.SpatialMaxPooling(2x2, 2,2)\n",
       "  (14): nn.SpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)\n",
       "  (15): nn.ReLU\n",
       "  (16): nn.StyleLoss\n",
       "  (17): nn.SpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)\n",
       "  (18): nn.ReLU\n",
       "  (19): nn.SpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)\n",
       "  (20): nn.ReLU\n",
       "  (21): nn.SpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)\n",
       "  (22): nn.ReLU\n",
       "  (23): nn.SpatialMaxPooling(2x2, 2,2)\n",
       "  (24): nn.SpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)\n",
       "  (25): nn.ReLU\n",
       "  (26): nn.StyleLoss\n",
       "  (27): nn.SpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)\n",
       "  (28): nn.ReLU\n",
       "  (29): nn.ContentLoss\n",
       "  (30): nn.SpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)\n",
       "  (31): nn.ReLU\n",
       "  (32): nn.SpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)\n",
       "  (33): nn.ReLU\n",
       "  (34): nn.SpatialMaxPooling(2x2, 2,2)\n",
       "  (35): nn.SpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)\n",
       "  (36): nn.ReLU\n",
       "  (37): nn.StyleLoss\n",
       "}\n",
       "{\n",
       "  gradInput : FloatTensor - empty\n",
       "  modules : \n",
       "    {\n",
       "      1 : \n",
       "        nn.TVLoss\n",
       "        {\n",
       "          x_diff : FloatTensor - empty\n",
       "          _type : torch.FloatTensor\n",
       "          output : FloatTensor - empty\n",
       "          gradInput : FloatTensor - empty\n",
       "          strength : 0.001\n",
       "          y_diff : FloatTensor - empty\n",
       "        }\n",
       "      2 : \n",
       "        nn.SpatialConvolution(3 -> 64, 3x3, 1,1, 1,1)\n",
       "        {\n",
       "          padW : 1\n",
       "          nInputPlane : 3\n",
       "          output : FloatTensor - empty\n",
       "          name : conv1_1\n",
       "          _type : torch.FloatTensor\n",
       "          dH : 1\n",
       "          dW : 1\n",
       "          nOutputPlane : 64\n",
       "          padH : 1\n",
       "          kH : 3\n",
       "          weight : FloatTensor - size: 64x3x3x3\n",
       "          gradWeight : FloatTensor - size: 64x3x3x3\n",
       "          gradInput : FloatTensor - empty\n",
       "          kW : 3\n",
       "          bias : FloatTensor - size: 64\n",
       "          gradBias : FloatTensor - size: 64\n",
       "        }\n",
       "      3 : \n",
       "        nn.ReLU\n",
       "        {\n",
       "          inplace : true\n",
       "          threshold : 0\n",
       "          _type : torch.FloatTensor\n",
       "          output : FloatTensor - empty\n",
       "          gradInput : FloatTensor - empty\n",
       "          name : relu1_1\n",
       "          val : 0\n",
       "        }\n",
       "      4 : \n",
       "        nn.StyleLoss\n",
       "        {\n",
       "          output : FloatTensor - empty\n",
       "          gradInput : FloatTensor - empty\n",
       "          loss : 0\n",
       "          target : FloatTensor - empty\n",
       "          gram : \n",
       "            nn.GramMatrix\n",
       "            {\n",
       "              gradInput : FloatTensor - empty\n",
       "              _type : torch.FloatTensor\n",
       "              output : FloatTensor - empty\n",
       "    "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "        }\n",
       "          normalize : false\n",
       "          _type : torch.FloatTensor\n",
       "          strength : 100\n",
       "          crit : \n",
       "            nn.MSECriterion\n",
       "            {\n",
       "              gradInput : FloatTensor - empty\n",
       "              sizeAverage : true\n",
       "              output : 0\n",
       "            }\n",
       "          mode : none\n",
       "        }\n",
       "      5 : \n",
       "        nn.SpatialConvolution(64 -> 64, 3x3, 1,1, 1,1)\n",
       "        {\n",
       "          padW : 1\n",
       "          nInputPlane : 64\n",
       "          output : FloatTensor - empty\n",
       "          name : conv1_2\n",
       "          _type : torch.FloatTensor\n",
       "          dH : 1\n",
       "          dW : 1\n",
       "          nOutputPlane : 64\n",
       "          padH : 1\n",
       "          kH : 3\n",
       "          weight : FloatTensor - size: 64x64x3x3\n",
       "          gradWeight : FloatTensor - size: 64x64x3x3\n",
       "          gradInput : FloatTensor - empty\n",
       "          kW : 3\n",
       "          bias : FloatTensor - size: 64\n",
       "          gradBias : FloatTensor - size: 64\n",
       "        }\n",
       "      6 : \n",
       "        nn.ReLU\n",
       "        {\n",
       "          inplace : true\n",
       "          threshold : 0\n",
       "          _type : torch.FloatTensor\n",
       "          output : FloatTensor - empty\n",
       "          gradInput : FloatTensor - empty\n",
       "          name : relu1_2\n",
       "          val : 0\n",
       "        }\n",
       "      7 : \n",
       "        nn.SpatialMaxPooling(2x2, 2,2)\n",
       "        {\n",
       "          dH : 2\n",
       "          dW : 2\n",
       "          kW : 2\n",
       "          gradInput : FloatTensor - empty\n",
       "          indices : FloatTensor - empty\n",
       "          name : pool1\n",
       "          _type : torch.FloatTensor\n",
       "          padH : 0\n",
       "          ceil_mode : true\n",
       "          output : FloatTensor - empty\n",
       "          kH : 2\n",
       "          padW : 0\n",
       "        }\n",
       "      8 : \n",
       "        nn.SpatialConvolution(64 -> 128, 3x3, 1,1, 1,1)\n",
       "        {\n",
       "          padW : 1\n",
       "          nInputPlane : 64\n",
       "          output : FloatTensor - empty\n",
       "          name : conv2_1\n",
       "          _type : torch.FloatTensor\n",
       "          dH : 1\n",
       "          dW : 1\n",
       "          nOutputPlane : 128\n",
       "          padH : 1\n",
       "          kH : 3\n",
       "          weight : FloatTensor - size: 128x64x3x3\n",
       "          gradWeight : FloatTensor - size: 128x64x3x3\n",
       "          gradInput : FloatTensor - empty\n",
       "          kW : 3\n",
       "          bias : FloatTensor - size: 128\n",
       "          gradBias : FloatTensor - size: 128\n",
       "        }\n",
       "      9 : \n",
       "        nn.ReLU\n",
       "        {\n",
       "          inplace : true\n",
       "          threshold : 0\n",
       "          _type : torch.FloatTensor\n",
       "          output : FloatTensor - empty\n",
       "          gradInput : FloatTensor - empty\n",
       "          name : relu2_1\n",
       "          val : 0\n",
       "        }\n",
       "      10 : \n",
       "        nn.StyleLoss\n",
       "        {\n",
       "          output : FloatTensor - empty\n",
       "          gradInput : FloatTensor - empty\n",
       "          loss : 0\n",
       "          target : FloatTensor - empty\n",
       "          gram : \n",
       "            nn.GramMatrix\n",
       "            {\n",
       "              gradInput : FloatTensor - empty\n",
       "              _type : torch.FloatTensor\n",
       "              output : FloatTensor - empty\n",
       "            }\n",
       "          normalize : false\n",
       "          _type : torch.FloatTensor\n",
       "          strength : 100\n",
       "          crit : \n",
       "            nn.MSECriterion\n",
       "            {\n",
       "              gradInput : FloatTensor - empty\n",
       "              sizeAverage : true\n",
       "              output : 0\n",
       "            }\n",
       "          mode : none\n",
       "        "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "}\n",
       "      11 : \n",
       "        nn.SpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)\n",
       "        {\n",
       "          padW : 1\n",
       "          nInputPlane : 128\n",
       "          output : FloatTensor - empty\n",
       "          name : conv2_2\n",
       "          _type : torch.FloatTensor\n",
       "          dH : 1\n",
       "          dW : 1\n",
       "          nOutputPlane : 128\n",
       "          padH : 1\n",
       "          kH : 3\n",
       "          weight : FloatTensor - size: 128x128x3x3\n",
       "          gradWeight : FloatTensor - size: 128x128x3x3\n",
       "          gradInput : FloatTensor - empty\n",
       "          kW : 3\n",
       "          bias : FloatTensor - size: 128\n",
       "          gradBias : FloatTensor - size: 128\n",
       "        }\n",
       "      12 : \n",
       "        nn.ReLU\n",
       "        {\n",
       "          inplace : true\n",
       "          threshold : 0\n",
       "          _type : torch.FloatTensor\n",
       "          output : FloatTensor - empty\n",
       "          gradInput : FloatTensor - empty\n",
       "          name : relu2_2\n",
       "          val : 0\n",
       "        }\n",
       "      13 : \n",
       "        nn.SpatialMaxPooling(2x2, 2,2)\n",
       "        {\n",
       "          dH : 2\n",
       "          dW : 2\n",
       "          kW : 2\n",
       "          gradInput : FloatTensor - empty\n",
       "          indices : FloatTensor - empty\n",
       "          name : pool2\n",
       "          _type : torch.FloatTensor\n",
       "          padH : 0\n",
       "          ceil_mode : true\n",
       "          output : FloatTensor - empty\n",
       "          kH : 2\n",
       "          padW : 0\n",
       "        }\n",
       "      14 : \n",
       "        nn.SpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)\n",
       "        {\n",
       "          padW : 1\n",
       "          nInputPlane : 128\n",
       "          output : FloatTensor - empty\n",
       "          name : conv3_1\n",
       "          _type : torch.FloatTensor\n",
       "          dH : 1\n",
       "          dW : 1\n",
       "          nOutputPlane : 256\n",
       "          padH : 1\n",
       "          kH : 3\n",
       "          weight : FloatTensor - size: 256x128x3x3\n",
       "          gradWeight : FloatTensor - size: 256x128x3x3\n",
       "          gradInput : FloatTensor - empty\n",
       "          kW : 3\n",
       "          bias : FloatTensor - size: 256\n",
       "          gradBias : FloatTensor - size: 256\n",
       "        }\n",
       "      15 : \n",
       "        nn.ReLU\n",
       "        {\n",
       "          inplace : true\n",
       "          threshold : 0\n",
       "          _type : torch.FloatTensor\n",
       "          output : FloatTensor - empty\n",
       "          gradInput : FloatTensor - empty\n",
       "          name : relu3_1\n",
       "          val : 0\n",
       "        }\n",
       "      16 : \n",
       "        nn.StyleLoss\n",
       "        {\n",
       "          output : FloatTensor - empty\n",
       "          gradInput : FloatTensor - empty\n",
       "          loss : 0\n",
       "          target : FloatTensor - empty\n",
       "          gram : \n",
       "            nn.GramMatrix\n",
       "            {\n",
       "              gradInput : FloatTensor - empty\n",
       "              _type : torch.FloatTensor\n",
       "              output : FloatTensor - empty\n",
       "            }\n",
       "          normalize : false\n",
       "          _type : torch.FloatTensor\n",
       "          strength : 100\n",
       "       "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "   crit : \n",
       "            nn.MSECriterion\n",
       "            {\n",
       "              gradInput : FloatTensor - empty\n",
       "              sizeAverage : true\n",
       "              output : 0\n",
       "            }\n",
       "          mode : none\n",
       "        }\n",
       "      17 : \n",
       "        nn.SpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)\n",
       "        {\n",
       "          padW : 1\n",
       "          nInputPlane : 256\n",
       "          output : FloatTensor - empty\n",
       "          name : conv3_2\n",
       "          _type : torch.FloatTensor\n",
       "          dH : 1\n",
       "          dW : 1\n",
       "          nOutputPlane : 256\n",
       "          padH : 1\n",
       "          kH : 3\n",
       "          weight : FloatTensor - size: 256x256x3x3\n",
       "          gradWeight : FloatTensor - size: 256x256x3x3\n",
       "          gradInput : FloatTensor - empty\n",
       "          kW : 3\n",
       "          bias : FloatTensor - size: 256\n",
       "          gradBias : FloatTensor - size: 256\n",
       "        }\n",
       "      18 : \n",
       "        nn.ReLU\n",
       "        {\n",
       "          inplace : true\n",
       "          threshold : 0\n",
       "          _type : torch.FloatTensor\n",
       "          output : FloatTensor - empty\n",
       "          gradInput : FloatTensor - empty\n",
       "          name : relu3_2\n",
       "          val : 0\n",
       "        }\n",
       "      19 : \n",
       "        nn.SpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)\n",
       "        {\n",
       "          padW : 1\n",
       "          nInputPlane : 256\n",
       "          output : FloatTensor - empty\n",
       "          name : conv3_3\n",
       "          _type : torch.FloatTensor\n",
       "          dH : 1\n",
       "          dW : 1\n",
       "          nOutputPlane : 256\n",
       "          padH : 1\n",
       "          kH : 3\n",
       "          weight : FloatTensor - size: 256x256x3x3\n",
       "          gradWeight : FloatTensor - size: 256x256x3x3\n",
       "          gradInput : FloatTensor - empty\n",
       "          kW : 3\n",
       "          bias : FloatTensor - size: 256\n",
       "          gradBias : FloatTensor - size: 256\n",
       "        }\n",
       "      20 : \n",
       "        nn.ReLU\n",
       "        {\n",
       "          inplace : true\n",
       "          threshold : 0\n",
       "          _type : torch.FloatTensor\n",
       "          output : FloatTensor - empty\n",
       "          gradInput : FloatTensor - empty\n",
       "          name : relu3_3\n",
       "          val : 0\n",
       "        }\n",
       "      21 : \n",
       "        nn.SpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)\n",
       "        {\n",
       "          padW : 1\n",
       "          nInputPlane : 256\n",
       "          output : FloatTensor - empty\n",
       "          name : conv3_4\n",
       "          _type : torch.FloatTensor\n",
       "          dH : 1\n",
       "          dW : 1\n",
       "          nOutputPlane : 256\n",
       "          padH : 1\n",
       "          kH : 3\n",
       "          weight : FloatTensor - size: 256x256x3x3\n",
       "          gradWeight : FloatTensor - size: 256x256x3x3\n",
       "          gradInput : FloatTensor - empty\n",
       "          kW : 3\n",
       "          bias : FloatTensor - size: 256\n",
       "          gradBias : FloatTensor - size: 256\n",
       "        }\n",
       "      22 : \n",
       "        nn.ReLU\n",
       "        {\n",
       "          inplace : true\n",
       "          threshold : 0\n",
       "          _type : torch.FloatTensor\n",
       "          output : FloatTensor - empty\n",
       "          gradInput : FloatTensor - empty\n",
       "          name : relu3_4\n",
       "          val : 0\n",
       "        }\n",
       "      23 : \n",
       "        nn.SpatialMaxPooling(2x2, 2,2)\n",
       "        {\n",
       "    "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "      dH : 2\n",
       "          dW : 2\n",
       "          kW : 2\n",
       "          gradInput : FloatTensor - empty\n",
       "          indices : FloatTensor - empty\n",
       "          name : pool3\n",
       "          _type : torch.FloatTensor\n",
       "          padH : 0\n",
       "          ceil_mode : true\n",
       "          output : FloatTensor - empty\n",
       "          kH : 2\n",
       "          padW : 0\n",
       "        }\n",
       "      24 : \n",
       "        nn.SpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)\n",
       "        {\n",
       "          padW : 1\n",
       "          nInputPlane : 256\n",
       "          output : FloatTensor - empty\n",
       "          name : conv4_1\n",
       "          _type : torch.FloatTensor\n",
       "          dH : 1\n",
       "          dW : 1\n",
       "          nOutputPlane : 512\n",
       "          padH : 1\n",
       "          kH : 3\n",
       "          weight : FloatTensor - size: 512x256x3x3\n",
       "          gradWeight : FloatTensor - size: 512x256x3x3\n",
       "          gradInput : FloatTensor - empty\n",
       "          kW : 3\n",
       "          bias : FloatTensor - size: 512\n",
       "          gradBias : FloatTensor - size: 512\n",
       "        }\n",
       "      25 : \n",
       "        nn.ReLU\n",
       "        {\n",
       "          inplace : true\n",
       "          threshold : 0\n",
       "          _type : torch.FloatTensor\n",
       "          output : FloatTensor - empty\n",
       "          gradInput : FloatTensor - empty\n",
       "          name : relu4_1\n",
       "          val : 0\n",
       "        }\n",
       "      26 : \n",
       "        nn.StyleLoss\n",
       "        {\n",
       "          output : FloatTensor - empty\n",
       "          gradInput : FloatTensor - empty\n",
       "          loss : 0\n",
       "          target : FloatTensor - empty\n",
       "          gram : \n",
       "            nn.GramMatrix\n",
       "            {\n",
       "              gradInput : FloatTensor - empty\n",
       "              _type : torch.FloatTensor\n",
       "              output : FloatTensor - empty\n",
       "            }\n",
       "          normalize : false\n",
       "          _type : torch.FloatTensor\n",
       "          strength : 100\n",
       "          crit : \n",
       "            nn.MSECriterion\n",
       "            {\n",
       "              gradInput : FloatTensor - empty\n",
       "              sizeAverage : true\n",
       "              output : 0\n",
       "            }\n",
       "          mode : none\n",
       "        }\n",
       "      27 : \n",
       "        nn.SpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)\n",
       "        {\n",
       "          padW : 1\n",
       "          nInputPlane : 512\n",
       "          output : FloatTensor - empty\n",
       "          name : conv4_2\n",
       "          _type : torch.FloatTensor\n",
       "          dH : 1\n",
       "          dW : 1\n",
       "          nOutputPlane : 512\n",
       "          padH : 1\n",
       "          kH : 3\n",
       "          weight : FloatTensor - size: 512x512x3x3\n",
       "          gradWeight : FloatTensor - size: 512x512x3x3\n",
       "          gradInput : FloatTensor - empty\n",
       "          kW : 3\n",
       "          bias : FloatTensor - size: 512\n",
       "          gradBias : FloatTensor - size: 512\n",
       "        }\n",
       "      28 : \n",
       "        nn.ReLU\n",
       "        {\n",
       "          inplace : true\n",
       "          threshold : 0\n",
       "          _type : torch.FloatTensor\n",
       "          output : FloatTensor - empty\n",
       "    "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "      gradInput : FloatTensor - empty\n",
       "          name : relu4_2\n",
       "          val : 0\n",
       "        }\n",
       "      29 : \n",
       "        nn.ContentLoss\n",
       "        {\n",
       "          output : FloatTensor - empty\n",
       "          gradInput : FloatTensor - empty\n",
       "          loss : 0\n",
       "          target : FloatTensor - empty\n",
       "          normalize : false\n",
       "          _type : torch.FloatTensor\n",
       "          strength : 5\n",
       "          crit : \n",
       "            nn.MSECriterion\n",
       "            {\n",
       "              gradInput : FloatTensor - empty\n",
       "              sizeAverage : true\n",
       "              output : 0\n",
       "            }\n",
       "          mode : capture\n",
       "        }\n",
       "      30 : \n",
       "        nn.SpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)\n",
       "        {\n",
       "          padW : 1\n",
       "          nInputPlane : 512\n",
       "          output : FloatTensor - empty\n",
       "          name : conv4_3\n",
       "          _type : torch.FloatTensor\n",
       "          dH : 1\n",
       "          dW : 1\n",
       "          nOutputPlane : 512\n",
       "          padH : 1\n",
       "          kH : 3\n",
       "          weight : FloatTensor - size: 512x512x3x3\n",
       "          gradWeight : FloatTensor - size: 512x512x3x3\n",
       "          gradInput : FloatTensor - empty\n",
       "          kW : 3\n",
       "          bias : FloatTensor - size: 512\n",
       "          gradBias : FloatTensor - size: 512\n",
       "        }\n",
       "      31 : \n",
       "        nn.ReLU\n",
       "        {\n",
       "          inplace : true\n",
       "          threshold : 0\n",
       "          _type : torch.FloatTensor\n",
       "          output : FloatTensor - empty\n",
       "          gradInput : FloatTensor - empty\n",
       "          name : relu4_3\n",
       "          val : 0\n",
       "        }\n",
       "      32 : \n",
       "        nn.SpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)\n",
       "        {\n",
       "          padW : 1\n",
       "          nInputPlane : 512\n",
       "          output : FloatTensor - empty\n",
       "          name : conv4_4\n",
       "          _type : torch.FloatTensor\n",
       "          dH : 1\n",
       "          dW : 1\n",
       "          nOutputPlane : 512\n",
       "          padH : 1\n",
       "          kH : 3\n",
       "          weight : FloatTensor - size: 512x512x3x3\n",
       "          gradWeight : FloatTensor - size: 512x512x3x3\n",
       "          gradInput : FloatTensor - empty\n",
       "          kW : 3\n",
       "          bias : FloatTensor - size: 512\n",
       "          gradBias : FloatTensor - size: 512\n",
       "        }\n",
       "      33 : \n",
       "        nn.ReLU\n",
       "        {\n",
       "          inplace : true\n",
       "          threshold : 0\n",
       "          _type : torch.FloatTensor\n",
       "          output : FloatTensor - empty\n",
       "          gradInput : FloatTensor - empty\n",
       "          name : relu4_4\n",
       "          val : 0\n",
       "        }\n",
       "      34 : \n",
       "        nn.SpatialMaxPooling(2x2, 2,2)\n",
       "        {\n",
       "          dH : 2\n",
       "          dW : 2\n",
       "          kW : 2\n",
       "          gradInput : FloatTensor - empty\n",
       "          indices : FloatTensor - empty\n",
       "          name : pool4\n",
       "          _type : torch.FloatTensor\n",
       "          padH : 0\n",
       "          ceil_mode : true\n",
       "          output : FloatTensor - empty\n",
       "          kH : 2\n",
       "          padW : 0\n",
       "        }\n",
       "      35 : \n",
       "        nn.SpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)\n",
       "        {\n",
       "          padW : 1\n",
       "          nInputPlane : 512\n",
       "          output : FloatTensor - empty\n",
       "          name : conv5_1\n",
       "          _type : torch.FloatTensor\n",
       "          dH : 1\n",
       "          dW : 1\n",
       "          nOutputPlane : 512\n",
       "          padH : 1\n",
       "          kH : 3\n",
       "          weight : FloatTensor - size: 512x512x3x3\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "          gradWeight : FloatTensor - size: 512x512x3x3\n",
       "          gradInput : FloatTensor - empty\n",
       "          kW : 3\n",
       "          bias : FloatTensor - size: 512\n",
       "          gradBias : FloatTensor - size: 512\n",
       "        }\n",
       "      36 : \n",
       "        nn.ReLU\n",
       "        {\n",
       "          inplace : true\n",
       "          threshold : 0\n",
       "          _type : torch.FloatTensor\n",
       "          output : FloatTensor - empty\n",
       "          gradInput : FloatTensor - empty\n",
       "          name : relu5_1\n",
       "          val : 0\n",
       "        }\n",
       "      37 : \n",
       "        nn.StyleLoss\n",
       "        {\n",
       "          output : FloatTensor - empty\n",
       "          gradInput : FloatTensor - empty\n",
       "          loss : 0\n",
       "          target : FloatTensor - empty\n",
       "          gram : \n",
       "            nn.GramMatrix\n",
       "            {\n",
       "              gradInput : FloatTensor - empty\n",
       "              _type : torch.FloatTensor\n",
       "              output : FloatTensor - empty\n",
       "            }\n",
       "          normalize : false\n",
       "          _type : torch.FloatTensor\n",
       "          strength : 100\n",
       "          crit : \n",
       "            nn.MSECriterion\n",
       "            {\n",
       "              gradInput : FloatTensor - empty\n",
       "              sizeAverage : true\n",
       "              output : 0\n",
       "            }\n",
       "          mode : none\n",
       "        }\n",
       "    }\n",
       "  _type : torch.FloatTensor\n",
       "  output : FloatTensor - empty\n",
       "}\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  -- Capture content targets\n",
    "  for i = 1, #content_losses do\n",
    "    content_losses[i].mode = 'capture'\n",
    "  end\n",
    "  print 'Capturing content targets'\n",
    "  print(net)\n",
    "  content_image_caffe = content_image_caffe:type(dtype)\n",
    "  net:forward(content_image_caffe:type(dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Capturing style target 1\t\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Capture style targets\n",
    "for i = 1, #content_losses do\n",
    "    content_losses[i].mode = 'none'\n",
    "end\n",
    "for i = 1, #style_images_caffe do\n",
    "    print(string.format('Capturing style target %d', i))\n",
    "    for j = 1, #style_losses do\n",
    "        style_losses[j].mode = 'capture'\n",
    "        style_losses[j].blend_weight = style_blend_weights[i]\n",
    "    end\n",
    "    net:forward(style_images_caffe[i]:type(dtype))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "  -- Set all loss modules to loss mode\n",
    "  for i = 1, #content_losses do\n",
    "    content_losses[i].mode = 'loss'\n",
    "  end\n",
    "  for i = 1, #style_losses do\n",
    "    style_losses[i].mode = 'loss'\n",
    "  end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "  -- We don't need the base CNN anymore, so clean it up to save memory.\n",
    "  cnn = nil\n",
    "  for i=1, #net.modules do\n",
    "    local module = net.modules[i]\n",
    "    if torch.type(module) == 'nn.SpatialConvolutionMM' then\n",
    "        -- remove these, not used, but uses gpu memory\n",
    "        module.gradWeight = nil\n",
    "        module.gradBias = nil\n",
    "    end\n",
    "  end\n",
    "  collectgarbage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "  -- Initialize the image\n",
    "  if params.seed >= 0 then\n",
    "    torch.manualSeed(params.seed)\n",
    "  end\n",
    "  img = nil\n",
    "  if params.init == 'random' then\n",
    "    img = torch.randn(content_image:size()):float():mul(0.001)\n",
    "  elseif params.init == 'image' then\n",
    "    if init_image then\n",
    "      img = init_image:clone()\n",
    "    else\n",
    "      img = content_image_caffe:clone()\n",
    "    end\n",
    "  else\n",
    "    error('Invalid init type')\n",
    "  end\n",
    "img = img:type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "  -- Run it through the network once to get the proper size for the gradient\n",
    "  -- All the gradients will come from the extra loss modules, so we just pass\n",
    "  -- zeros into the top of the net on the backward pass.\n",
    "y = net:forward(img)\n",
    "dy = img.new(#y):zero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Declaring this here lets us access it in maybe_print\n",
    "  optim_state = nil\n",
    "  if params.optimizer == 'lbfgs' then\n",
    "    optim_state = {\n",
    "      maxIter = params.num_iterations,\n",
    "      verbose=true,\n",
    "      tolX=-1,\n",
    "      tolFun=-1,\n",
    "    }\n",
    "    if params.lbfgs_num_correction > 0 then\n",
    "      optim_state.nCorrection = params.lbfgs_num_correction\n",
    "    end\n",
    "  elseif params.optimizer == 'adam' then\n",
    "    optim_state = {\n",
    "      learningRate = params.learning_rate,\n",
    "    }\n",
    "  else\n",
    "    error(string.format('Unrecognized optimizer \"%s\"', params.optimizer))\n",
    "  end\n",
    "\n",
    "  function maybe_print(t, loss)\n",
    "    local verbose = (params.print_iter > 0 and t % params.print_iter == 0)\n",
    "    if verbose then\n",
    "      print(string.format('Iteration %d / %d', t, params.num_iterations))\n",
    "      for i, loss_module in ipairs(content_losses) do\n",
    "        print(string.format('  Content %d loss: %f', i, loss_module.loss))\n",
    "      end\n",
    "      for i, loss_module in ipairs(style_losses) do\n",
    "        print(string.format('  Style %d loss: %f', i, loss_module.loss))\n",
    "      end\n",
    "      print(string.format('  Total loss: %f', loss))\n",
    "    end\n",
    "  end\n",
    "\n",
    "  function maybe_save(t)\n",
    "    local should_save = params.save_iter > 0 and t % params.save_iter == 0\n",
    "    should_save = should_save or t == params.num_iterations\n",
    "    if should_save then\n",
    "      local disp = deprocess(img:double())\n",
    "      disp = image.minmax{tensor=disp, min=0, max=1}\n",
    "      local filename = build_filename(params.output_image, t)\n",
    "      if t == params.num_iterations then\n",
    "        filename = params.output_image\n",
    "      end\n",
    "              -- Maybe perform postprocessing for color-independent style transfer\n",
    "      if params.original_colors == 1 then\n",
    "        disp = original_colors(content_image, disp)\n",
    "      end\n",
    "\n",
    "      image.save(filename, disp)\n",
    "    end\n",
    "  end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "  -- Function to evaluate loss and gradient. We run the net forward and\n",
    "  -- backward to get the gradient, and sum up losses from the loss modules.\n",
    "  -- optim.lbfgs internally handles iteration and calls this function many\n",
    "  -- times, so we manually count the number of iterations to handle printing\n",
    "  -- and saving intermediate results.\n",
    "  num_calls = 0\n",
    "  function feval(x)\n",
    "    num_calls = num_calls + 1\n",
    "    net:forward(x)\n",
    "    local grad = net:updateGradInput(x, dy)\n",
    "    local loss = 0\n",
    "    for _, mod in ipairs(content_losses) do\n",
    "      loss = loss + mod.loss\n",
    "    end\n",
    "    for _, mod in ipairs(style_losses) do\n",
    "      loss = loss + mod.loss\n",
    "    end\n",
    "    maybe_print(num_calls, loss)\n",
    "    maybe_save(num_calls)\n",
    "\n",
    "    collectgarbage()\n",
    "    -- optim.lbfgs expects a vector for gradients\n",
    "    return loss, grad:view(grad:nElement())\n",
    "  end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running optimization with L-BFGS\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "...s/Nishiyama/torch/install/share/lua/5.1/nn/Container.lua:67: \nIn 1 module of nn.Sequential:\n[string \"TVLoss, parent = torch.class('nn.TVLoss', 'nn...\"]:29: invalid arguments: FloatTensor nil \nexpected arguments: *FloatTensor* [FloatTensor] float | *FloatTensor* [FloatTensor] [float] FloatTensor\nstack traceback:\n\t[C]: in function 'add'\n\t[string \"TVLoss, parent = torch.class('nn.TVLoss', 'nn...\"]:29: in function <[string \"TVLoss, parent = torch.class('nn.TVLoss', 'nn...\"]:16>\n\t[C]: in function 'xpcall'\n\t...s/Nishiyama/torch/install/share/lua/5.1/nn/Container.lua:63: in function 'rethrowErrors'\n\t.../Nishiyama/torch/install/share/lua/5.1/nn/Sequential.lua:58: in function 'updateGradInput'\n\t[string \"  -- Function to evaluate loss and gradient. ...\"]:10: in function 'opfunc'\n\t...rs/Nishiyama/torch/install/share/lua/5.1/optim/lbfgs.lua:66: in function 'lbfgs'\n\t[string \"  -- Run optimization....\"]:4: in main chunk\n\t[C]: in function 'xpcall'\n\t...rs/Nishiyama/torch/install/share/lua/5.1/itorch/main.lua:210: in function <...rs/Nishiyama/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...rs/Nishiyama/torch/install/share/lua/5.1/lzmq/poller.lua:80: in function 'poll'\n\t...Nishiyama/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...Nishiyama/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...Nishiyama/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...rs/Nishiyama/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x0105045ea0\n\nWARNING: If you see a stack trace below, it doesn't point to the place where this error occurred. Please use only the one above.\nstack traceback:\n\t[C]: in function 'error'\n\t...s/Nishiyama/torch/install/share/lua/5.1/nn/Container.lua:67: in function 'rethrowErrors'\n\t.../Nishiyama/torch/install/share/lua/5.1/nn/Sequential.lua:58: in function 'updateGradInput'\n\t[string \"  -- Function to evaluate loss and gradient. ...\"]:10: in function 'opfunc'\n\t...rs/Nishiyama/torch/install/share/lua/5.1/optim/lbfgs.lua:66: in function 'lbfgs'\n\t[string \"  -- Run optimization....\"]:4: in main chunk\n\t[C]: in function 'xpcall'\n\t...rs/Nishiyama/torch/install/share/lua/5.1/itorch/main.lua:210: in function <...rs/Nishiyama/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...rs/Nishiyama/torch/install/share/lua/5.1/lzmq/poller.lua:80: in function 'poll'\n\t...Nishiyama/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...Nishiyama/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...Nishiyama/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...rs/Nishiyama/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x0105045ea0",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "...s/Nishiyama/torch/install/share/lua/5.1/nn/Container.lua:67: \nIn 1 module of nn.Sequential:\n[string \"TVLoss, parent = torch.class('nn.TVLoss', 'nn...\"]:29: invalid arguments: FloatTensor nil \nexpected arguments: *FloatTensor* [FloatTensor] float | *FloatTensor* [FloatTensor] [float] FloatTensor\nstack traceback:\n\t[C]: in function 'add'\n\t[string \"TVLoss, parent = torch.class('nn.TVLoss', 'nn...\"]:29: in function <[string \"TVLoss, parent = torch.class('nn.TVLoss', 'nn...\"]:16>\n\t[C]: in function 'xpcall'\n\t...s/Nishiyama/torch/install/share/lua/5.1/nn/Container.lua:63: in function 'rethrowErrors'\n\t.../Nishiyama/torch/install/share/lua/5.1/nn/Sequential.lua:58: in function 'updateGradInput'\n\t[string \"  -- Function to evaluate loss and gradient. ...\"]:10: in function 'opfunc'\n\t...rs/Nishiyama/torch/install/share/lua/5.1/optim/lbfgs.lua:66: in function 'lbfgs'\n\t[string \"  -- Run optimization....\"]:4: in main chunk\n\t[C]: in function 'xpcall'\n\t...rs/Nishiyama/torch/install/share/lua/5.1/itorch/main.lua:210: in function <...rs/Nishiyama/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...rs/Nishiyama/torch/install/share/lua/5.1/lzmq/poller.lua:80: in function 'poll'\n\t...Nishiyama/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...Nishiyama/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...Nishiyama/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...rs/Nishiyama/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x0105045ea0\n\nWARNING: If you see a stack trace below, it doesn't point to the place where this error occurred. Please use only the one above.\nstack traceback:\n\t[C]: in function 'error'\n\t...s/Nishiyama/torch/install/share/lua/5.1/nn/Container.lua:67: in function 'rethrowErrors'\n\t.../Nishiyama/torch/install/share/lua/5.1/nn/Sequential.lua:58: in function 'updateGradInput'\n\t[string \"  -- Function to evaluate loss and gradient. ...\"]:10: in function 'opfunc'\n\t...rs/Nishiyama/torch/install/share/lua/5.1/optim/lbfgs.lua:66: in function 'lbfgs'\n\t[string \"  -- Run optimization....\"]:4: in main chunk\n\t[C]: in function 'xpcall'\n\t...rs/Nishiyama/torch/install/share/lua/5.1/itorch/main.lua:210: in function <...rs/Nishiyama/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...rs/Nishiyama/torch/install/share/lua/5.1/lzmq/poller.lua:80: in function 'poll'\n\t...Nishiyama/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...Nishiyama/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...Nishiyama/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...rs/Nishiyama/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x0105045ea0"
     ]
    }
   ],
   "source": [
    "  -- Run optimization.\n",
    "  if params.optimizer == 'lbfgs' then\n",
    "    print('Running optimization with L-BFGS')\n",
    "    local x, losses = optim.lbfgs(feval, img, optim_state)\n",
    "  elseif params.optimizer == 'adam' then\n",
    "    print('Running optimization with ADAM')\n",
    "    for t = 1, params.num_iterations do\n",
    "      local x, losses = optim.adam(feval, img, optim_state)\n",
    "    end\n",
    "  end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
